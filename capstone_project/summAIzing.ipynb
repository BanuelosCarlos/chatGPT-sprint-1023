{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import os\n",
    "import pydub\n",
    "from pydub.utils import which\n",
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "AudioSegment.converter = which(\"ffmpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/watch?v=S2gixYsCItU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the destination (leave blank for current directory)\n",
      "Build a Chatbot in Python| ChatGPT API Complete Tutorial for Beginners has been successfully downloaded.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    yt = YouTube( \n",
    "        str(url)) \n",
    "except Exception as ee:\n",
    "    print(ee)\n",
    "# extract only audio \n",
    "audio = yt.streams.filter(only_audio=True).first() \n",
    "  \n",
    "# check for destination to save file \n",
    "print(\"Enter the destination (leave blank for current directory)\") \n",
    "destination = str(input(\">> \")) or '.'\n",
    "  \n",
    "# download the file \n",
    "out_file = audio.download(output_path=destination) \n",
    "  \n",
    "# save the file \n",
    "base, ext = os.path.splitext(out_file) \n",
    "new_file = (base + '.mp3').replace(\" \", \"_\")\n",
    "os.rename(out_file, new_file) \n",
    "  \n",
    "# result of success \n",
    "print(yt.title + \" has been successfully downloaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_stats = os.stat(new_file)\n",
    "file_size = file_stats.st_size / (1024*1024) # In MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mp3_audio = pydub.AudioSegment.from_file(new_file, \"mp3\")\n",
    "except Exception as ee:\n",
    "    mp3_audio = pydub.AudioSegment.from_file(new_file, \"mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for counter in range(num_chunks):\n",
    "    start = counter * chunk_size\n",
    "    end = min(start + chunk_size, len(mp3_audio))\n",
    "    chunk = mp3_audio[start:end]\n",
    "    chunk.export(\"output_\" + str(counter + 1) + \".mp3\", format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AudioSegment' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     mp3_audio \u001b[39m=\u001b[39m pydub\u001b[39m.\u001b[39;49mAudioSegment\u001b[39m.\u001b[39;49mfrom_file(input_file, \u001b[39m\"\u001b[39;49m\u001b[39mmp3\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ee:\n",
      "File \u001b[0;32m~/Documents/chatGPT-project/chatGPT-sprint-1023/openai-venv/lib/python3.10/site-packages/pydub/audio_segment.py:723\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m     stdin_parameter \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPIPE\n\u001b[0;32m--> 723\u001b[0m     stdin_data \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    725\u001b[0m \u001b[39mif\u001b[39;00m codec:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AudioSegment' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         chunk_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_folder, chunk_filename)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         chunk\u001b[39m.\u001b[39mexport(chunk_path, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmp3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m split_mp3_file(mp3_audio)\n",
      "\u001b[1;32m/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     mp3_audio \u001b[39m=\u001b[39m pydub\u001b[39m.\u001b[39mAudioSegment\u001b[39m.\u001b[39mfrom_file(input_file, \u001b[39m\"\u001b[39m\u001b[39mmp3\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ee:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     mp3_audio \u001b[39m=\u001b[39m pydub\u001b[39m.\u001b[39;49mAudioSegment\u001b[39m.\u001b[39;49mfrom_file(input_file, \u001b[39m\"\u001b[39;49m\u001b[39mmp4\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m num_chunks \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(audio) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m chunk_size \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/aleksei/Documents/chatGPT-project/chatGPT-sprint-1023/capstone_project/summAIzing.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m output_folder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mchunks\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/chatGPT-project/chatGPT-sprint-1023/openai-venv/lib/python3.10/site-packages/pydub/audio_segment.py:723\u001b[0m, in \u001b[0;36mAudioSegment.from_file\u001b[0;34m(cls, file, format, codec, parameters, start_second, duration, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         conversion_command \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m-i\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    722\u001b[0m     stdin_parameter \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPIPE\n\u001b[0;32m--> 723\u001b[0m     stdin_data \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m    725\u001b[0m \u001b[39mif\u001b[39;00m codec:\n\u001b[1;32m    726\u001b[0m     info \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AudioSegment' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "\n",
    "def split_mp3_file(input_file):\n",
    "    chunk_size = 10 * 1024 * 1024 \n",
    "    try:\n",
    "        mp3_audio = pydub.AudioSegment.from_file(input_file, \"mp3\")\n",
    "    except Exception as ee:\n",
    "        mp3_audio = pydub.AudioSegment.from_file(input_file, \"mp4\")\n",
    "    num_chunks = len(audio) // chunk_size + 1\n",
    "\n",
    "    output_folder = \"chunks\"\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for i in range(num_chunks):\n",
    "        start = i * chunk_size\n",
    "        end = min(start + chunk_size, len(audio))\n",
    "        chunk = audio[start:end]\n",
    "\n",
    "        chunk_filename = f\"output_{i + 1}.mp3\"\n",
    "        chunk_path = os.path.join(output_folder, chunk_filename)\n",
    "        chunk.export(chunk_path, format=\"mp3\")\n",
    "\n",
    "\n",
    "split_mp3_file(mp3_audio)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
